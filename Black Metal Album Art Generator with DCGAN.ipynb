{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing the libraries\nfrom __future__ import print_function\nimport torch\nfrom torch.utils.data import ConcatDataset\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\nimport os\nfrom PIL import Image\n\n\nos.makedirs('/kaggle/working/results')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda_checked = False\nif torch.cuda.is_available() and not cuda_checked:\n    device = torch.device(\"cuda\")\n    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n    cuda_checked = True\nelse:\n    device = torch.device(\"cpu\")\n    print(\"Using CPU for computation\")\n\n\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, root, transform=None):\n        self.root = root\n        self.transform = transform\n        self.samples = self.load_samples()\n\n    def __getitem__(self, index):\n        try:\n            sample_path = self.samples[index]\n            sample = Image.open(sample_path).convert(\"RGB\")  # Open image as RGB\n\n            if self.transform is not None:\n                sample = self.transform(sample)\n\n            return sample\n        except OSError as e:\n            print(f\"Error processing image at index {index}: {e}\")\n            return None\n\n    def __len__(self):\n        return len(self.samples)\n\n    def load_samples(self):\n        sample_list = []\n        for root, _, filenames in os.walk(self.root):\n            for filename in filenames:\n                if (\n                    filename.endswith(\".jpeg\")\n                    or filename.endswith(\".png\")\n                    or filename.endswith(\".jpg\")\n                ):\n                    sample_path = os.path.join(root, filename)\n                    sample_list.append(sample_path)\n                    #print(f\"Loaded sample: {sample_path}\")\n        return sample_list\n\n\n\n\n\nbatchSize = 64 \nimageSize = (64, 64) \n\n# Creating the transformations\ntransform = transforms.Compose([transforms.Resize(imageSize), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) \n\ndataset1 = CustomDataset(root='/kaggle/input/metal-album-art-by-subgenre/data/black_metal', transform=transform)\ndataset2 = CustomDataset(root='/kaggle/input/metal-album-art-by-subgenre/data/power_metal', transform=transform)\n\nmerged_dataset = ConcatDataset([dataset1, dataset2])\nmerged_length = len(merged_dataset)\nprint(\"Length of the merged dataset:\", merged_length)\n\ndataloader = torch.utils.data.DataLoader(merged_dataset, batch_size = batchSize, shuffle = True, num_workers = 2) \n\n# Defining the weights_init function that takes as input a neural network m and that will initialize all its weights.\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n\n        \n        \n        \n# Defining the generator\nclass G(nn.Module):\n\n    def __init__(self):\n        super(G, self).__init__()\n        self.main = nn.Sequential( \n            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False), \n            nn.BatchNorm2d(512), \n            nn.ReLU(True), \n            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False), \n            nn.BatchNorm2d(256),\n            nn.ReLU(True), \n            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False), \n            nn.BatchNorm2d(128), \n            nn.ReLU(True), \n            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False), \n            nn.BatchNorm2d(64), \n            nn.ReLU(True), \n            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False), \n            nn.Tanh() \n        )\n\n    def forward(self, input): \n        output = self.main(input) \n        return output \n\n# Creating the generator\nnetG = G()\nnetG.apply(weights_init) \n\n\n# Defining the discriminator\nclass D(nn.Module):\n\n    def __init__(self): \n        super(D, self).__init__() \n        self.main = nn.Sequential( \n            nn.Conv2d(3, 64, 4, 2, 1, bias = False), \n            nn.LeakyReLU(0.2, inplace = True),\n            nn.Conv2d(64, 128, 4, 2, 1, bias = False), \n            nn.BatchNorm2d(128), \n            nn.LeakyReLU(0.2, inplace = True), \n            nn.Conv2d(128, 256, 4, 2, 1, bias = False), \n            nn.BatchNorm2d(256), # We normalize again.\n            nn.LeakyReLU(0.2, inplace = True), \n            nn.Conv2d(256, 512, 4, 2, 1, bias = False), \n            nn.BatchNorm2d(512), \n            nn.LeakyReLU(0.2, inplace = True), \n            nn.Conv2d(512, 1, 4, 1, 0, bias = False), \n            nn.Sigmoid() \n        )\n\n    def forward(self, input): \n        output = self.main(input) \n        return output.view(-1)\n\n# Creating the discriminator\nnetD = D()\nnetD.apply(weights_init) \n\n# Training the DCGANs\n\ncriterion = nn.BCELoss().to(device) \noptimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999)) \noptimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999)) \n\nnetG = netG.to(device)\nnetD = netD.to(device)\n\n\nfor epoch in range(700): # We iterate over 700 epochs.\n\n    for i, data in enumerate(dataloader, 0): # We iterate over the images of the dataset.\n        \n        # 1st Step: Updating the weights of the neural network of the discriminator\n\n        netD.zero_grad()\n        \n        # Training the discriminator with a real image of the dataset\n        real = data.to(device) \n        input = Variable(real).to(device) \n        target = Variable(torch.ones(input.size()[0])).to(device) \n        output = netD(input).to(device) \n        errD_real = criterion(output, target).to(device) \n        \n        # Training the discriminator with a fake image generated by the generator\n        noise = Variable(torch.randn(input.size()[0], 100, 1, 1)).to(device) \n        fake = netG(noise) \n        target = Variable(torch.zeros(input.size()[0])).to(device) \n        output = netD(fake.detach()) \n        errD_fake = criterion(output, target) \n\n        # Backpropagating the total error\n        errD = errD_real + errD_fake \n        errD.backward()\n        optimizerD.step()\n\n        # 2nd Step: Updating the weights of the neural network of the generator\n\n        netG.zero_grad() \n        target = Variable(torch.ones(input.size()[0])).to(device) \n        output = netD(fake).to(device) \n        errG = criterion(output, target).to(device) \n        errG.backward() \n        optimizerG.step() \n\n        #Printing the losses and saving the real images and the generated images of the minibatch every 100 steps\n\n        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 700, i, len(dataloader), errD.item(), errG.item()))\n        if i % 100 == 0:\n            vutils.save_image(real, '%s/real_samples.png' % \"/kaggle/working/results\", normalize = True)\n            fake = netG(noise) \n            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"/kaggle/working/results\", epoch), normalize = True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}